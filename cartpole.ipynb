{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnHostetter/AAMAS-2023-FCQL/blob/main/cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contained within this notebook is a sample implementation and demo of the proposed **Fuzzy Conservative Q-Learning** procedure. The code is not necessarily optimal or efficient with respect to performance, but was more or less written for interpretability. Some functions that may be difficult to follow, such as ECM, actually should have a one-to-one correspondence with the original paper's notation (in the case of ECM, that would be the dynamic evolving neuro fuzzy system called DENFIS). "
      ],
      "metadata": {
        "id": "Vku-98nBJI_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gym==0.22.0\n",
        "%pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvp2VHmtHQPx",
        "outputId": "12fdaa2f-c41b-46ec-af6a-6e75b0e1bb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym==0.22.0 in /usr/local/lib/python3.8/dist-packages (0.22.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.22.0) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym==0.22.0) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.22.0) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.22.0) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym==0.22.0) (3.13.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the following can be installed without pip install\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gym\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim\n",
        "from datetime import datetime\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.parameter import Parameter\n",
        "from scipy.spatial.distance import minkowski  # for Evolving Clustering Method (ECM)\n",
        "from sklearn.metrics import mean_squared_error  # for neuro-fuzzy network core functionality\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "v8LlmhnRFf37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
      ],
      "metadata": {
        "id": "zRH_hnjBRhWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few libraries we need to pip install."
      ],
      "metadata": {
        "id": "U3Yo7ZspYdi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "iVR8__KsWFG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to pip install d3rlpy (deep reinforcement learning) library\n",
        "\n",
        "!pip install d3rlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfQpTbo3FlsJ",
        "outputId": "801e55a2-37e2-4fdc-fdf7-e3b865197301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: d3rlpy in /usr/local/lib/python3.8/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (1.0.2)\n",
            "Requirement already satisfied: structlog in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (22.3.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (0.22.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (4.5.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (1.7.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (4.64.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (0.4.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from d3rlpy) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym->d3rlpy) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->d3rlpy) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym->d3rlpy) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym->d3rlpy) (6.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->d3rlpy) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->d3rlpy) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX->d3rlpy) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->d3rlpy) (3.19.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym->d3rlpy) (3.13.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from d3rlpy.datasets import get_cartpole"
      ],
      "metadata": {
        "id": "E1qlakPRNsfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first algorithm we need to define is **Categorical Learning Induced Partitioning (CLIP)**. CLIP is used to generate the Gaussian membership functions that describe fuzzy sets. By running CLIP over the entire training data, we will be able to create a global language (i.e. linguistic terms) for interpretation."
      ],
      "metadata": {
        "id": "YoH38xTfYqLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian(x, center, sigma):\n",
        "    return np.exp(-1.0 * (np.power(x - center, 2) / np.power(sigma, 2)))\n",
        "\n",
        "def R(sigma_1, sigma_2):\n",
        "    # regulator function\n",
        "    return (1/2) * (sigma_1 + sigma_2)\n",
        "\n",
        "def CLIP(X, mins, maxes, terms=[], eps=0.2, kappa=0.6, theta=1e-8):\n",
        "    # theta is a parameter I add to accomodate for the instance in which an observation has values that are the minimum/maximum\n",
        "    # otherwise, when determining the Gaussian membership, a division by zero will occur\n",
        "    # it essentially acts as an error tolerance\n",
        "    antecedents = terms\n",
        "    min_values_per_feature_in_X = mins\n",
        "    max_values_per_feature_in_X = maxes\n",
        "    for idx, x in enumerate(X):\n",
        "        if not terms:\n",
        "            # no fuzzy clusters yet, create the first fuzzy cluster\n",
        "            for p in range(len(x)):\n",
        "                c_1p = x[p]\n",
        "                min_p = min_values_per_feature_in_X[p]\n",
        "                max_p = max_values_per_feature_in_X[p]\n",
        "                left_width = np.sqrt(-1.0 * (np.power((min_p - x[p]) + theta, 2) / np.log(eps)))\n",
        "                right_width = np.sqrt(-1.0 * (np.power((max_p - x[p]) + theta, 2) / np.log(eps)))\n",
        "                sigma_1p = R(left_width, right_width)\n",
        "                terms.append([{'center': c_1p, 'sigma': sigma_1p, 'support':1}])\n",
        "        else:\n",
        "            # calculate the similarity between the input and existing fuzzy clusters\n",
        "            for p in range(len(x)):\n",
        "                SM_jps = []\n",
        "                for j, A_jp in enumerate(terms[p]):\n",
        "                    SM_jp = gaussian(x[p], A_jp['center'], A_jp['sigma'])\n",
        "                    SM_jps.append(SM_jp)\n",
        "                j_star_p = np.argmax(SM_jps)\n",
        "\n",
        "                if np.max(SM_jps) > kappa:\n",
        "                    # the best matched cluster is deemed as being able to give satisfactory description of the presented value\n",
        "                    A_j_star_p = terms[p][j_star_p]\n",
        "                    A_j_star_p['support'] += 1\n",
        "                else:\n",
        "                    # a new cluster is created in the input dimension based on the presented value\n",
        "                    jL_p = None\n",
        "                    jR_p = None\n",
        "                    jL_p_differences = []\n",
        "                    jR_p_differences = []\n",
        "                    for j, A_jp in enumerate(terms[p]):\n",
        "                        c_jp = A_jp['center']\n",
        "                        if c_jp >= x[p]:\n",
        "                            continue  # the newly created cluster has no immediate left neighbor\n",
        "                        else:\n",
        "                            jL_p_differences.append(np.abs(c_jp - x[p]))\n",
        "                    try:\n",
        "                        jL_p = np.argmin(jL_p_differences)\n",
        "                    except ValueError:\n",
        "                        jL_p = None\n",
        "\n",
        "                    for j, A_jp in enumerate(terms[p]):\n",
        "                        c_jp = A_jp['center']\n",
        "                        if c_jp <= x[p]:\n",
        "                            continue  # the newly created cluster has no immediate right neighbor\n",
        "                        else:\n",
        "                            jR_p_differences.append(np.abs(c_jp - x[p]))\n",
        "                    try:\n",
        "                        jR_p = np.argmin(jR_p_differences)\n",
        "                    except ValueError:\n",
        "                        jR_p = None\n",
        "\n",
        "                    new_c = x[p]\n",
        "                    new_sigma = None\n",
        "\n",
        "                    # --- this new fuzzy set has no left or right neighbor ---\n",
        "                    if jL_p is None and jR_p is None:\n",
        "                        continue\n",
        "\n",
        "                    # --- there is no left neighbor to this new fuzzy set ---\n",
        "                    if jL_p is None:\n",
        "                        cR_jp = terms[p][jR_p]['center']\n",
        "                        sigma_R_jp = terms[p][jR_p]['sigma']\n",
        "                        left_sigma_R = np.sqrt(-1.0 * (np.power(cR_jp - x[p], 2) / np.log(eps)))\n",
        "                        sigma_R = R(left_sigma_R, sigma_R_jp)\n",
        "\n",
        "                        new_sigma = sigma_R\n",
        "                        # update the existing term to make room for the new term\n",
        "                        terms[p][jR_p]['sigma'] = new_sigma\n",
        "\n",
        "                    # --- there is no right neighbor to this new fuzzy set ---\n",
        "                    elif jR_p is None:\n",
        "                        cL_jp = terms[p][jL_p]['center']\n",
        "                        sigma_L_jp = terms[p][jL_p]['sigma']\n",
        "                        left_sigma_L = np.sqrt(-1.0 * (np.power(cL_jp - x[p], 2) / np.log(eps)))\n",
        "                        sigma_L = R(left_sigma_L, sigma_L_jp)\n",
        "\n",
        "                        new_sigma = sigma_L\n",
        "                        # update the existing term to make room for the new term\n",
        "                        terms[p][jL_p]['sigma'] = new_sigma\n",
        "\n",
        "                    # --- there is BOTH a left and a right neighbor to this fuzzy set ---\n",
        "                    else:\n",
        "                        cR_jp = terms[p][jR_p]['center']\n",
        "                        sigma_R_jp = terms[p][jR_p]['sigma']\n",
        "                        left_sigma_R = np.sqrt(-1.0 * (np.power(cR_jp - x[p], 2) / np.log(eps)))\n",
        "                        sigma_R = R(left_sigma_R, sigma_R_jp)\n",
        "\n",
        "                        cL_jp = terms[p][jL_p]['center']\n",
        "                        sigma_L_jp = terms[p][jL_p]['sigma']\n",
        "                        left_sigma_L = np.sqrt(-1.0 * (np.power(cL_jp - x[p], 2) / np.log(eps)))\n",
        "                        sigma_L = R(left_sigma_L, sigma_L_jp)\n",
        "\n",
        "                        new_sigma = R(sigma_R, sigma_L)\n",
        "                        # update the existing terms to make room for the new term\n",
        "                        terms[p][jR_p]['sigma'] = terms[p][jL_p]['sigma'] = new_sigma\n",
        "                    terms[p].append({'center':new_c, 'sigma':new_sigma, 'support':1})\n",
        "    return terms"
      ],
      "metadata": {
        "id": "sDZTPmgMF4NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evolving Clustering Method is required for fuzzy logic rule generation. Below we define its necessary functions."
      ],
      "metadata": {
        "id": "IywgThzBIJtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUPPRESS_EXCEPTIONS = True\n",
        "\n",
        "class Cluster:\n",
        "    def __init__(self, center, radius):\n",
        "        self.center = center\n",
        "        self.radius = radius\n",
        "        self.support = 1\n",
        "        \n",
        "    def add_support(self):\n",
        "        self.support += 1\n",
        "        \n",
        "        \n",
        "def general_euclidean_distance(x, y):\n",
        "    if len(x) == len(y): \n",
        "        q = len(x)\n",
        "        return minkowski(x, y, p=2) / np.power(q, 0.5)\n",
        "    else:\n",
        "        raise TypeError('The vectors must of of equal dimensionality in order to use the General Euclidean Distance metric.')\n",
        "\n",
        "\n",
        "def ECM(X, Cs, Dthr, SUPPRESS_EXCEPTIONS=True):\n",
        "    for i, x in enumerate(X):\n",
        "        if len(Cs) == 0:\n",
        "            \"\"\"\n",
        "            Step 0: Create the first cluster by simply taking the\n",
        "            position of the first example from the input stream as the\n",
        "            first cluster center Cc_{1}^{0}, and setting a value 0 for its cluster\n",
        "            radius Ru_{1} [Fig. 2(a)].\n",
        "            \"\"\"\n",
        "            C = Cluster(center=x, radius=0)\n",
        "            Cs.append(C)\n",
        "            \n",
        "        \"\"\"\n",
        "        Step 1: If all examples of the data stream have been processed, the algorithm \n",
        "        is finished. Else, the current input example, $x_i$, is taken and the distances \n",
        "        between this example and all $n$ already created cluster \n",
        "        centers Cc_j, D_{ij} = ||x_{i} - Cc_{j}||, j = 1, 2, ..., n, are calculated.  \n",
        "        \"\"\"\n",
        "        \n",
        "        D_i = {}  # distances between the i'th 'x' and the centers for each j'th cluster; dictionary is indexed by j\n",
        "        for j, C in enumerate(Cs):\n",
        "            D_i[j] = general_euclidean_distance(x, C.center)\n",
        "            \n",
        "            \"\"\"\n",
        "            Step 2: If there is any distance value, D_{ij} = ||x_{i} - Cc_{j}||, equal to, \n",
        "            or less than, at least one of the radii, Ru_{j}, j = 1, 2, ..., n, it means \n",
        "            that the current example belongs to a cluster C_{m} with the minimum distance\n",
        "            \n",
        "            D_{im} = ||x_{i} - Cc_{m}|| = min(||x_{i} - Cc_{j}||)\n",
        "            \n",
        "            subject to the constraint D_{ij} < Ru_{j},   j = 1, 2, ..., n.\n",
        "            \n",
        "            In this case, neither a new cluster is created, nor are any existing clusters \n",
        "            updated (the cases of $x_4$ and $x_6$ in Fig. 2); the algorithm returns to Step 1. \n",
        "            Else—go to the next step.\n",
        "            \"\"\"\n",
        "            if D_i[j] < C.radius:\n",
        "                C.add_support()\n",
        "                break  # the observation belongs to this cluster, C. Return to Step 1.\n",
        "                \n",
        "        if D_i[j] < C.radius:\n",
        "            continue  # the observation belongs to this cluster, C. Return to Step 1.\n",
        "        \n",
        "        \"\"\" \n",
        "        Step 3: Find cluster (with center Cc_{a} and cluster radius Ru_{a}) from all existing cluster \n",
        "        centers through calculating the values S_{ij} = D_{ij} + Ru_{j}, j = 1, 2, ..., n, and then \n",
        "        choosing the cluster center with the minimum value S_{ia}:\n",
        "            \n",
        "            S_{ia} = D_{ia} + Ru_{a} = min(S_{ij}), j = 1, 2, ..., n.\n",
        "        \"\"\"\n",
        "        \n",
        "        S_i = {}\n",
        "        for item in D_i.items():\n",
        "            j = item[0]\n",
        "            D_j = item[1]\n",
        "            C_j = Cs[j]\n",
        "            Ru_j = C_j.radius\n",
        "            S_i[j] = D_j + Ru_j\n",
        "        a = min(S_i, key=S_i.get)\n",
        "        S_ia = S_i[a]\n",
        "        \n",
        "        \"\"\"\n",
        "        Step 4: If S_{ia} is greater than $2 * Dthr$, the example $x_i$ does not belong to any \n",
        "        existing clusters. A new cluster is created in the same way as described in Step 0 \n",
        "        (the cases of $x_3$ and $x_8$ in Fig. 2), and the algorithm returns to Step 1.\n",
        "        \"\"\"\n",
        "        \n",
        "        if S_ia > (2.0 * Dthr):\n",
        "            \"\"\"\n",
        "            Step 0: Create the first cluster by simply taking the\n",
        "            position of the first example from the input stream as the\n",
        "            first cluster center Cc_{1}^{0}, and setting a value 0 for its cluster\n",
        "            radius Ru_{1} [Fig. 2(a)].\n",
        "            \"\"\"\n",
        "            C = Cluster(center=x, radius=0)\n",
        "            Cs.append(C)\n",
        "            continue  # terminate further execution of this iteration\n",
        "        else:\n",
        "            \"\"\"\n",
        "            Step 5: If S_{ia} is not greater than $2 * Dthr$, the cluster $C_{a}$ is updated by moving \n",
        "            its center, Cc_{a}, and increasing the value of its radius, Ru_{a}. The updated \n",
        "            radius Ru_{a}^{new} is set to be equal to S_{ia} / 2 and the new center Cc_{a}^{new} is located\n",
        "            at the point on the line connecting the $x_i$ and Cc_{a}, and the distance from the new \n",
        "            center Cc_{a}^{new} to the point $x_{i}$ is equal to Ru_{a}^{new} \n",
        "            (the cases of $x_2$, $x_5$, $x_7$ and $x_9$ in Fig. 2).\n",
        "            The algorithm returns to Step 1\n",
        "            \"\"\"\n",
        "            Ca = Cs[a]\n",
        "            Ca.radius = S_ia / 2.0\n",
        "            Ca.add_support()            \n",
        "            n = Ca.support\n",
        "            \n",
        "            if n == 0:\n",
        "                m_n_minus_1 = 0\n",
        "            else:\n",
        "                m_n_minus_1 = Ca.center\n",
        "                \n",
        "            # keep a running mean approximation of the cluster center\n",
        "            \n",
        "            Ca.center = ((n - 1) * Ca.center + x) / n\n",
        "            \n",
        "            if not SUPPRESS_EXCEPTIONS and general_euclidean_distance(Ca.center, x) != Ca.radius:\n",
        "                raise Exception('The distance from the center of the relevant cluster is meant to be equal to the cluster\\'s radius.')\n",
        "    return Cs"
      ],
      "metadata": {
        "id": "vrWhe0dvIIOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, after ECM, is the Wang-Mendel method for fuzzy logic rule generation. It comes with a few extras that go beyond just the Wang-Mendel method as described in the paper because it is a general implementation. Specifically, it includes certainty factor calculations as described in the HyFIS paper. These certainty factors are ignored in our current procedure."
      ],
      "metadata": {
        "id": "dDJgdlKBKIau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rule_creation(X, antecedents, existing_rules=[], existing_weights=[], consistency_check=True):\n",
        "    start = time.time()\n",
        "    rules = existing_rules\n",
        "    weights = existing_weights\n",
        "    for x in X:\n",
        "        CF = 1.0 # certainty factor of this rule\n",
        "        # this block of code is for antecedents\n",
        "        A_star_js = []\n",
        "        for p in range(len(x)):\n",
        "            SM_jps = []\n",
        "            for j, A_jp in enumerate(antecedents[p]):\n",
        "                SM_jp = gaussian(x[p], A_jp['center'], A_jp['sigma'])\n",
        "                SM_jps.append(SM_jp)\n",
        "            CF *= np.max(SM_jps)\n",
        "            j_star_p = np.argmax(SM_jps)\n",
        "            A_star_js.append(j_star_p)\n",
        "\n",
        "        # with some work, you can remove the 'C' key-value here in the rule, it stands for 'consequent(s)'\n",
        "        # however, later on, in the neuro-fuzzy Q-network, it will expect this to be here\n",
        "        R_star = {'A':A_star_js, 'C': [0], 'CF': CF, 'time_added': start}\n",
        "\n",
        "        if not rules:  # no rules in knowledge base yet\n",
        "            rules.append(R_star)\n",
        "            weights.append(1.0)\n",
        "        else:  # there are rules in the knowledge base, so check for uniqueness (i.e., this new rule you made -- R_star -- is it needed?)\n",
        "            add_new_rule = True\n",
        "            for k, rule in enumerate(rules):\n",
        "                try:\n",
        "                    if (rule['A'] == R_star['A']) and (rule['C'] == R_star['C']):\n",
        "                        # the generated rule is not unique, it already exists, enhance this rule's weight\n",
        "                        weights[k] += 1.0\n",
        "                        rule['CF'] = min(rule['CF'], R_star['CF'])\n",
        "                        add_new_rule = False\n",
        "                        break\n",
        "                except ValueError:  # this happens because R_star['A'] and R_star['C'] are Numpy arrays\n",
        "                    if all(rule['A'] == list(R_star['A'])) and all(rule['C'] == list(R_star['C'])):\n",
        "                        # the generated rule is not unique, it already exists, enhance this rule's weight\n",
        "                        weights[k] += 1.0\n",
        "                        rule['CF'] = min(rule['CF'], R_star['CF'])\n",
        "                        add_new_rule = False\n",
        "                        break\n",
        "                    elif all(rule['A'] == list(R_star['A'])):  # my own custom else-if statement\n",
        "                        if rule['CF'] <= R_star['CF']:\n",
        "                            add_new_rule = False\n",
        "            if add_new_rule:\n",
        "                rules.append(R_star)\n",
        "                weights.append(1.0)\n",
        "\n",
        "    # check for consistency\n",
        "    if consistency_check:\n",
        "        all_antecedents = [rule['A'] for rule in rules]\n",
        "    \n",
        "        repeated_rule_indices = set()\n",
        "        for k in range(len(rules)):\n",
        "            indices = np.where(np.all(all_antecedents == np.array(rules[k]['A']), axis=1))[0]\n",
        "            if len(indices) > 1:\n",
        "                if len(repeated_rule_indices) == 0:  # this can be combined with the following elif-statement\n",
        "                    repeated_rule_indices.add(tuple(indices))\n",
        "                elif len(repeated_rule_indices) > 0:  # this can be combined with the above if-statement\n",
        "                    repeated_rule_indices.add(tuple(indices))\n",
        "    \n",
        "        for indices in repeated_rule_indices:\n",
        "            weights_to_compare = [weights[idx] for idx in indices]\n",
        "            strongest_rule_index = indices[np.argmax(weights_to_compare)]  # keep the rule with the greatest weight to it\n",
        "            for index in indices:\n",
        "                if index != strongest_rule_index:\n",
        "                    rules[index] = None\n",
        "                    weights[index] = None\n",
        "        rules = [rules[k] for k, rule in enumerate(rules) if rules[k] is not None]\n",
        "        weights = [weights[k] for k, weight in enumerate(weights) if weights[k] is not None]\n",
        "    \n",
        "        # need to check that no antecedent terms are \"orphaned\" (i.e., they go unused)\n",
        "    \n",
        "        all_antecedents = [rule['A'] for rule in rules]\n",
        "        all_antecedents = np.array(all_antecedents)\n",
        "        for p in range(len(x)):\n",
        "            if len(antecedents[p]) == len(np.unique(all_antecedents[:,p])):\n",
        "                continue\n",
        "            else:\n",
        "                # orphaned antecedent term\n",
        "                indices_for_antecedents_that_are_used = set(all_antecedents[:,p])\n",
        "                updated_indices_to_map_to = list(range(len(indices_for_antecedents_that_are_used)))\n",
        "                antecedents[p] = [antecedents[p][index] for index in indices_for_antecedents_that_are_used]\n",
        "    \n",
        "                paired_indices = list(zip(indices_for_antecedents_that_are_used, updated_indices_to_map_to))\n",
        "                for index_pair in paired_indices:  # the paired indices are sorted w.r.t. the original indices\n",
        "                    original_index = index_pair[0]  # so, when we updated the original index to its new index\n",
        "                    new_index = index_pair[1]  # we are guaranteed not to overwrite the last updated index\n",
        "                    all_antecedents[:,p][all_antecedents[:,p] == original_index] = new_index\n",
        "    \n",
        "        # update the rules in case any orphaned terms occurred\n",
        "        for idx, rule in enumerate(rules):\n",
        "            rule['A'] = all_antecedents[idx]\n",
        "\n",
        "    return antecedents, rules, weights"
      ],
      "metadata": {
        "id": "Y8eJBeXwKETO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above three methods are now combined together into a single function called `unsupervised()`."
      ],
      "metadata": {
        "id": "p3wMiwbIM0e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unsupervised(train_X, ecm=True, Dthr=1e-3, verbose=False):\n",
        "    \"\"\"\n",
        "    Applies CLIP, ECM and Wang-Mendel method to produce the fuzzy sets, candidates and fuzzy logic rules, respectively.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_X : 2-D Numpy array\n",
        "        The input vector, has a shape of (number of observations, number of inputs/attributes).\n",
        "    ecm : boolean, optional\n",
        "        This boolean controls whether to enable the ECM algorithm for candidate rule generation. The default is True.\n",
        "    Dthr : float, optional\n",
        "        The distance threshold for the ECM algorithm; only matters if ECM is enabled. The default is 1e-3.\n",
        "    verbose : boolean, optional\n",
        "        If enabled (True), the execution of this function will print out step-by-step to show progress. The default is False.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    The fuzzy logic rules, their corresponding weights (unused), and the antecedent terms they are defined over.\n",
        "\n",
        "    \"\"\"\n",
        "    print('The shape of the training data is: (%d, %d)\\n' %\n",
        "          (train_X.shape[0], train_X.shape[1]))\n",
        "    train_X_mins = train_X.min(axis=0)\n",
        "    train_X_maxes = train_X.max(axis=0)\n",
        "\n",
        "    if verbose:\n",
        "        print('Creating/updating the membership functions...')\n",
        "\n",
        "    eps = 0.2\n",
        "    kappa = 0.6\n",
        "\n",
        "    start = time.time()\n",
        "    antecedents = CLIP(train_X, train_X_mins, train_X_maxes,\n",
        "                       [], eps=eps, kappa=kappa)\n",
        "    end = time.time()\n",
        "    if verbose:\n",
        "        print('membership functions for the antecedents generated in %.2f seconds.' % (\n",
        "                end - start))\n",
        "\n",
        "    if ecm:\n",
        "        if verbose:\n",
        "            print('\\nReducing the data observations to clusters using ECM...')\n",
        "        start = time.time()\n",
        "        clusters = ECM(train_X, [], Dthr)\n",
        "        if verbose:\n",
        "            print('%d clusters were found with ECM from %d observations...' % (\n",
        "                len(clusters), train_X.shape[0]))\n",
        "        reduced_X = [cluster.center for cluster in clusters]\n",
        "        end = time.time()\n",
        "        if verbose:\n",
        "            print('done; the ECM algorithm completed in %.2f seconds.' %\n",
        "                  (end - start))\n",
        "    else:\n",
        "        reduced_X = train_X\n",
        "\n",
        "    if verbose:\n",
        "        print('\\nCreating/updating the fuzzy logic rules...')\n",
        "    start = time.time()\n",
        "    antecedents, rules, weights = rule_creation(reduced_X, antecedents, [], [],\n",
        "                                                             consistency_check=False)\n",
        "\n",
        "    K = len(rules)\n",
        "    end = time.time()\n",
        "    if verbose:\n",
        "        print('%d fuzzy logic rules created/updated in %.2f seconds.' %\n",
        "              (K, end - start))\n",
        "    return rules, weights, antecedents"
      ],
      "metadata": {
        "id": "b_cOwFPeM6On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Gaussian activation function is then defined where it can have different centers and widths depending on which input variable and input term it is describing. For example, the i'th fuzzy set (across all input dimensions) would be defined by its corresponding i'th center and sigma."
      ],
      "metadata": {
        "id": "c5Y3s8SVN1QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gaussian(nn.Module):\n",
        "    \"\"\"\n",
        "    Helpful reference: https://towardsdatascience.com/extending-pytorch-with-custom-activation-functions-2d8b065ef2fa\n",
        "\n",
        "    Implementation of the Gaussian membership function.\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "    Parameters:\n",
        "        - centers: trainable parameter\n",
        "        - sigmas: trainable parameter\n",
        "    Examples:\n",
        "        # >>> a1 = gaussian(256)\n",
        "        # >>> x = torch.randn(256)\n",
        "        # >>> x = a1(x)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, centers=None, sigmas=None, trainable=True):\n",
        "        \"\"\"\n",
        "        Initialization.\n",
        "        INPUT:\n",
        "            - in_features: shape of the input\n",
        "            - centers: trainable parameter\n",
        "            - sigmas: trainable parameter\n",
        "            centers and sigmas are initialized randomly by default,\n",
        "            but sigmas must be > 0\n",
        "        \"\"\"\n",
        "        super(Gaussian, self).__init__()\n",
        "        self.in_features = in_features\n",
        "\n",
        "        # initialize centers\n",
        "        if centers is None:\n",
        "            self.centers = Parameter(torch.randn(self.in_features))\n",
        "        else:\n",
        "            self.centers = torch.tensor(centers)\n",
        "\n",
        "        # initialize sigmas\n",
        "        if sigmas is None:\n",
        "            self.sigmas = Parameter(torch.abs(torch.randn(self.in_features)))\n",
        "        else:\n",
        "            # make sure the sigma values are positive\n",
        "            self.sigmas = torch.abs(torch.tensor(sigmas))\n",
        "\n",
        "        self.centers.requires_grad = trainable\n",
        "        self.sigmas.requiresGrad = trainable\n",
        "        self.centers.grad = None\n",
        "        self.sigmas.grad = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the function. Applies the function to the input elementwise.\n",
        "        \"\"\"\n",
        "\n",
        "        return torch.exp(-1.0 * (torch.pow(x - self.centers, 2) / torch.pow(self.sigmas, 2)))"
      ],
      "metadata": {
        "id": "iCh_NK5Pstk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    The terms 'Fuzzy Logic Controller' and 'Neuro-Fuzzy Network' are used interchangeably in this code."
      ],
      "metadata": {
        "id": "2AfAJjle6IgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FLC(nn.Module):\n",
        "    \"\"\"\n",
        "    Helpful reference: https://towardsdatascience.com/extending-pytorch-with-custom-activation-functions-2d8b065ef2fa\n",
        "\n",
        "    Implementation of the Fuzzy Logic Controller.\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "    Parameters:\n",
        "        - centers: trainable parameter\n",
        "        - sigmas: trainable parameter\n",
        "    Examples:\n",
        "        # >>> antecedents = [[{'type': 'gaussian', 'parameters': {'center': 1.2, 'sigma': 0.1}},\n",
        "                            {'type': 'gaussian', 'parameters': {'center': 3.0, 'sigma': 0.4}}],\n",
        "                            [{'type': 'gaussian', 'parameters': {'center': 0.2, 'sigma': 0.4}}]]\n",
        "        # consequences are not required, default is None\n",
        "        # >>> consequences = [[{'type': 'gaussian', 'parameters': {'center': 0.1, 'sigma': 0.7}},\n",
        "                            {'type': 'gaussian', 'parameters': {'center': 0.4, 'sigma': 0.41}}],\n",
        "                            [{'type': 'gaussian', 'parameters': {'center': 0.9, 'sigma': 0.32}}]]\n",
        "        # if consequences are not to be specified, leave the key-value out\n",
        "        # >>> rules = [{'antecedents':[0, 0], 'consequences':[0]}, {'antecedents':[1, 0], 'consequences':[1]}]\n",
        "        # >>> n_input = len(antecedents)  # the length of antecedents should be equal to number of inputs\n",
        "        # >>> n_output = len(consequences)  # the length of antecedents should be equal to number of inputs\n",
        "        # >>> flc = FLC(n_input, n_output, antecedents, rules, consequences)\n",
        "        # >>> x = torch.randn(n_input)\n",
        "        # >>> y = flc(x)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, antecedents, rules, consequences=None):\n",
        "        \"\"\"\n",
        "        Initialization.\n",
        "        INPUT:\n",
        "            - in_features: shape of the input\n",
        "            - consequences: (optional) trainable parameter\n",
        "            consequences are initialized randomly by default,\n",
        "            but sigmas must be > 0\n",
        "        \"\"\"\n",
        "        super(FLC, self).__init__()\n",
        "        self.in_features = in_features\n",
        "\n",
        "        # find the number of antecedents per input variable\n",
        "        num_of_antecedents = np.zeros(in_features).astype('int32')\n",
        "        unique_id = 0\n",
        "        gaussians = {'centers': [], 'sigmas': []}  # currently, we assume only Gaussians are used\n",
        "        self.input_variable_ids = []\n",
        "        self.transformed_x_length = 0\n",
        "        for input_variable_idx in range(in_features):\n",
        "            num_of_antecedents[input_variable_idx] = len(antecedents[input_variable_idx])\n",
        "            self.input_variable_ids.append(set())\n",
        "            for term_idx, antecedent in enumerate(antecedents[input_variable_idx]):\n",
        "                try:\n",
        "                    gaussians['centers'].append(antecedent['parameters']['center'])\n",
        "                    gaussians['sigmas'].append(antecedent['parameters']['sigma'])\n",
        "                except KeyError:\n",
        "                    gaussians['centers'].append(antecedent['center'])\n",
        "                    gaussians['sigmas'].append(antecedent['sigma'])\n",
        "                antecedent['id'] = unique_id\n",
        "                self.input_variable_ids[-1].add(unique_id)\n",
        "                unique_id += 1\n",
        "        self.transformed_x_length = unique_id\n",
        "\n",
        "        # find the total number of antecedents across all input variables\n",
        "        n_rules = len(rules)\n",
        "        self.links_between_antecedents_and_rules = np.zeros((num_of_antecedents.sum(), n_rules))\n",
        "\n",
        "        for rule_idx, rule in enumerate(rules):\n",
        "            try:\n",
        "                for input_variable_idx, term_idx in enumerate(rule['antecedents']):\n",
        "                    new_term_idx = antecedents[input_variable_idx][term_idx]['id']\n",
        "                    self.links_between_antecedents_and_rules[new_term_idx, rule_idx] = 1\n",
        "            except KeyError:\n",
        "                for input_variable_idx, term_idx in enumerate(rule['A']):\n",
        "                    new_term_idx = antecedents[input_variable_idx][term_idx]['id']\n",
        "                    self.links_between_antecedents_and_rules[new_term_idx, rule_idx] = 1\n",
        "\n",
        "        # begin creating the model's layers\n",
        "        self.input_terms = Gaussian(in_features=self.in_features, centers=gaussians['centers'],\n",
        "                                    sigmas=gaussians['sigmas'], trainable=False)\n",
        "\n",
        "        # initialize consequences\n",
        "        if consequences is None:\n",
        "            num_of_consequent_terms = len(rules)\n",
        "            self.consequences = Parameter(torch.zeros(num_of_consequent_terms, out_features))\n",
        "        else:\n",
        "            self.consequences = Parameter(torch.tensor(consequences))\n",
        "\n",
        "        self.consequences.requires_grad = True\n",
        "\n",
        "    def __transform(self, X):\n",
        "        \"\"\"\n",
        "        Transforms the given 'X' to make it compatible with the first layer.\n",
        "\n",
        "        The shape of 'X' is (num. of observations, num. of features).\n",
        "        \"\"\"\n",
        "        shape = X.shape\n",
        "        n_observations = shape[0]  # number of observations\n",
        "        new_X = np.zeros((n_observations, self.transformed_x_length))\n",
        "        for input_variable_idx, indices_to_repeat_for in enumerate(self.input_variable_ids):\n",
        "            min_column_idx = min(indices_to_repeat_for)\n",
        "            max_column_idx = max(indices_to_repeat_for) + 1\n",
        "            copies = len(indices_to_repeat_for)  # how many copies we should make of this column\n",
        "            new_X[:, min_column_idx:max_column_idx] = np.repeat(X[:, input_variable_idx], copies).reshape(\n",
        "                (n_observations, copies))\n",
        "        return torch.tensor(new_X)  # the shape of new_X should now be (num. of observations, num. of antecedent terms)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward pass of the function. Applies the function to the input elementwise.\n",
        "\n",
        "        The shape of 'X' is (num. of observations, num. of features).\n",
        "        \"\"\"\n",
        "        # we need to make the given 'X' compatible with our first layer,\n",
        "        # which means repeating it for some entries\n",
        "        antecedents_memberships = self.input_terms(self.__transform(X))\n",
        "        terms_to_rules = antecedents_memberships[:, :, None] * torch.tensor(self.links_between_antecedents_and_rules)\n",
        "        terms_to_rules[terms_to_rules == 0] = 1.0  # ignore zeroes, this is from the weights between terms and rules\n",
        "        # the shape of terms_to_rules is (num of observations, num of ALL terms, num of rules)\n",
        "        rules_applicability = terms_to_rules.prod(dim=1)\n",
        "        numerator = (rules_applicability * self.consequences.T[0]).sum(dim=1)  # MISO\n",
        "        denominator = rules_applicability.sum(dim=1)\n",
        "        denominator[denominator == 0] = 1e-300  # add a minimum rule applicability to avoid division by zero error\n",
        "        return numerator / denominator  # the dim=1 is taking product across ALL terms, now shape (num of observations, num of rules), MISO\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        A wrapper function, for calls that prefer the usage of 'predict'.\n",
        "\n",
        "        The shape of 'X' is (num. of observations, num. of features).\n",
        "        \"\"\"\n",
        "        return self.forward(X)"
      ],
      "metadata": {
        "id": "P-u2Lah-rjX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above created FLC class can only handle multi-input-single-output (MISO). In other words, we could only calculate the Q-value of a single possible action. However, to extend this to multiple actions (i.e., multiple-output), we use the well-known fact that a collection of multiple FLCs is commonly used for producing multiple outputs."
      ],
      "metadata": {
        "id": "I11GxfxrJMGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiFLC:\n",
        "    \"\"\"\n",
        "    A multi-input-multi-output (MIMO) Neuro-Fuzzy Network is a collection of\n",
        "    multiple multi-input-single-output (MISO) Neuro-Fuzzy Networks (Klir, 1992).\n",
        "\n",
        "    Essentially, for each possible action, we create a MISO Neuro-Fuzzy Q-Network\n",
        "    to learn that action's Q-values across all the fuzzy logic rules.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_outputs, antecedents, rules, learning_rate=3e-4, cql_alpha=0.5):\n",
        "        \"\"\"\n",
        "        Build the MIMO Neuro-Fuzzy Q-Network with an Adam optimizer for each individual FLC (per action).\n",
        "        \"\"\"\n",
        "        self.flcs = []\n",
        "        self.optimizers = []\n",
        "        self.cql_alpha = cql_alpha\n",
        "        for flc_idx in range(n_outputs):\n",
        "            flc = FLC(n_inputs, 1, antecedents, rules)\n",
        "            self.flcs.append(flc)\n",
        "            # https://stackoverflow.com/questions/42966393/is-it-good-learning-rate-for-adam-method\n",
        "            self.optimizers.append(optim.Adam(flc.parameters(), lr=learning_rate))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Using all Neuro-Fuzzy networks, output all Q-values using the entire MIMO Neuro-Fuzzy Q-network.\n",
        "\n",
        "        The shape of 'X' is (num. of observations, num. of features).\n",
        "        \"\"\"\n",
        "        output = []\n",
        "        for flc in self.flcs:\n",
        "            output.append(list(flc.predict(X).detach().numpy()))\n",
        "        return torch.tensor(output).T\n",
        "\n",
        "    def train(self, mode):\n",
        "        \"\"\"\n",
        "        Disable training for all Neuro-Fuzzy networks used in this MIMO Neuro-Fuzzy Q-network.\n",
        "        \"\"\"\n",
        "        for flc in self.flcs:\n",
        "            flc.train(mode)\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"\"\"\n",
        "        Zeroes the gradient for each Neuro-Fuzzy network that creates this MIMO Neuro-Fuzzy Q-network.\n",
        "        \"\"\"\n",
        "        for flc in self.flcs:\n",
        "            flc.zero_grad()\n",
        "\n",
        "    def fcql_loss_function(self, all_q_values, pred_qvalues, target_qvalues, action_indices, flc_idx):\n",
        "        \"\"\"\n",
        "        The Fuzzy Conservative Q-Learning loss function.\n",
        "        To ensure correct implementation, this code is an adaptation of the loss function provided from:\n",
        "\n",
        "        https://colab.research.google.com/drive/1oJOYlAIOl9d1JjlutPY66KmfPkwPCgEE?usp=sharing\n",
        "        \"\"\"\n",
        "        logsumexp_qvalues = torch.logsumexp(all_q_values, dim=-1)\n",
        "\n",
        "        tmp_pred_qvalues = all_q_values.gather(\n",
        "            1, action_indices.reshape(-1, 1)).squeeze()\n",
        "        cql_loss = logsumexp_qvalues - tmp_pred_qvalues\n",
        "\n",
        "        new_targets = target_qvalues[:, flc_idx]\n",
        "        loss = torch.mean((pred_qvalues - new_targets) ** 2)\n",
        "        return loss + self.cql_alpha * torch.mean(cql_loss)\n",
        "\n",
        "    def offline_update(self, states, target_q_values, action_indices):\n",
        "        \"\"\"\n",
        "        Updates each individual FLC's Q-values.\n",
        "        \"\"\"\n",
        "        self.train(True)  # make sure training is enabled\n",
        "        avg_loss = 0.\n",
        "        all_q_values = self.predict(states)\n",
        "        # the loss must be computed for each individual FLC\n",
        "        for flc_idx, flc in enumerate(self.flcs):\n",
        "            # compute the loss and its gradients\n",
        "            q_values = flc.predict(states)  # get the Q-values for this action using its corresponding FLC\n",
        "            loss = self.fcql_loss_function(all_q_values, q_values, target_q_values, action_indices, flc_idx)\n",
        "            loss.backward()\n",
        "\n",
        "            # apply the update\n",
        "            self.optimizers[flc_idx].step()\n",
        "            avg_loss += loss.item()\n",
        "        self.train(False)  # when not training, turn it off\n",
        "        return avg_loss / len(self.flcs)\n",
        "\n",
        "    def compute_loss(self, states, target_q_values, action_indices):\n",
        "        \"\"\"\n",
        "        Only compute the loss, but do not apply an update.\n",
        "        \"\"\"\n",
        "        self.train(False)  # just in case, disable training\n",
        "        avg_loss = 0.\n",
        "        all_q_values = self.predict(states)\n",
        "        for flc_idx, flc in enumerate(self.flcs):\n",
        "            q_values = flc.predict(states)  # get the Q-values for this action using its corresponding FLC\n",
        "            loss = self.fcql_loss_function(all_q_values, q_values, target_q_values, action_indices, flc_idx)\n",
        "            avg_loss += loss.item()\n",
        "        self.train(True)  # activate training\n",
        "        return avg_loss / len(self.flcs)"
      ],
      "metadata": {
        "id": "knh6JXl6utUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block comes from the `d3rlpy` library, but it has been modified to return both the average and standard deviation of the online evaluation."
      ],
      "metadata": {
        "id": "p_FIKrfT3Hx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_environment(env, n_trials=100, epsilon=0.0, render=False):\n",
        "    \"\"\" Returns scorer function of evaluation on environment.\n",
        "\n",
        "    This function returns scorer function, which is suitable to the standard\n",
        "    scikit-learn scorer function style.\n",
        "    The metrics of the scorer function is ideal metrics to evaluate the\n",
        "    resulted policies.\n",
        "\n",
        "    .. code-block:: python\n",
        "\n",
        "        import gym\n",
        "\n",
        "        from d3rlpy.algos import DQN\n",
        "        from d3rlpy.metrics.scorer import evaluate_on_environment\n",
        "\n",
        "\n",
        "        env = gym.make('CartPole-v0')\n",
        "\n",
        "        scorer = evaluate_on_environment(env)\n",
        "\n",
        "        cql = CQL()\n",
        "\n",
        "        mean_episode_return = scorer(cql)\n",
        "\n",
        "\n",
        "    Args:\n",
        "        env (gym.Env): gym-styled environment.\n",
        "        n_trials (int): the number of trials.\n",
        "        epsilon (float): noise factor for epsilon-greedy policy.\n",
        "        render (bool): flag to render environment.\n",
        "\n",
        "    Returns:\n",
        "        callable: scoerer function.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def scorer(algo, *args):\n",
        "        print('Evaluating online for {} episodes.'.format(n_trials))\n",
        "        episode_rewards = []\n",
        "        for _ in range(n_trials):\n",
        "            observation = env.reset()\n",
        "            episode_reward = 0.0\n",
        "            while True:\n",
        "                if np.random.random() < epsilon:\n",
        "                    action = env.action_space.sample()\n",
        "                else:\n",
        "                    action = torch.argmax(algo.predict(torch.tensor(np.array([observation])))).item()\n",
        "                observation, reward, done, _ = env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "                if render:\n",
        "                    env.render()\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "            episode_rewards.append(episode_reward)\n",
        "        return np.mean(episode_rewards), np.std(episode_rewards)\n",
        "\n",
        "    return scorer"
      ],
      "metadata": {
        "id": "UBH6-gsVS2Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is code for training, which was inspired by a mix of the [PyTorch training tutorial](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html) and the [Offline RL tutorial](https://colab.research.google.com/drive/1oJOYlAIOl9d1JjlutPY66KmfPkwPCgEE?usp=sharing)."
      ],
      "metadata": {
        "id": "NvfPXKNHHrPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_target_q_values(model, transition, gamma):\n",
        "    q_values = model.predict(transition['state']).float()\n",
        "    q_values_next = model.predict(transition['next state'])\n",
        "    # to index with action_indices, we need to convert to long data type\n",
        "    action_indices = transition['action'].long()\n",
        "    rewards = transition['reward'].float()\n",
        "    terminals = transition['terminal']\n",
        "    # detach first and then clone is slightly more efficient than clone first and then detach\n",
        "    # https://stackoverflow.com/questions/55266154/pytorch-preferred-way-to-copy-a-tensor\n",
        "    q_values[torch.arange(len(q_values)), action_indices.long()] = rewards.detach().clone()\n",
        "    max_q_values_next, max_q_values_next_indices = torch.max(q_values_next, dim=1)\n",
        "    max_q_values_next *= gamma\n",
        "    q_values[torch.arange(len(q_values)), action_indices] += torch.tensor(\n",
        "        [0.0 if done else float(max_q_values_next[idx]) for idx, done in enumerate(terminals)])\n",
        "    return transition['state'], q_values, action_indices\n",
        "\n",
        "\n",
        "def train_one_epoch(training_loader, model, epoch_index, tb_writer, gamma):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, transition in enumerate(training_loader):\n",
        "        # Every transition is {'state', 'action', 'reward', 'next state', 'terminal'}\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        model.zero_grad()\n",
        "\n",
        "        states, target_q_values, action_indices = make_target_q_values(model, transition, gamma)\n",
        "\n",
        "        loss = model.offline_update(transition['state'], target_q_values, action_indices)\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss\n",
        "        if i % 10 == 0:\n",
        "            last_loss = running_loss / 10  # loss per batch\n",
        "            # print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "def offline_q_learning(model, training_dataset, validation_dataset, max_epochs=100, batch_size=64, gamma=0.9):\n",
        "    train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "    epoch_number = 0\n",
        "\n",
        "    best_vloss = 1_000_000.\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "        # Make sure gradient tracking is on, and do a pass over the data\n",
        "        model.train(True)\n",
        "        avg_loss = train_one_epoch(train_loader, model, epoch_number, writer, gamma)\n",
        "\n",
        "        # We don't need gradients on to do reporting\n",
        "        model.train(False)\n",
        "\n",
        "        running_vloss = 0.0\n",
        "        for i, validation_transition in enumerate(val_loader):\n",
        "            _, target_q_values, action_indices = make_target_q_values(model, validation_transition, gamma)\n",
        "            vloss = model.compute_loss(validation_transition['state'], target_q_values, action_indices)\n",
        "            running_vloss += vloss\n",
        "\n",
        "        avg_vloss = running_vloss / (i + 1)\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "        # Log the running loss averaged per batch\n",
        "        # for both training and validation\n",
        "        writer.add_scalars('Training vs. Validation Loss',\n",
        "                           {'Training': avg_loss, 'Validation': avg_vloss},\n",
        "                           epoch_number + 1)\n",
        "        writer.flush()\n",
        "\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            # model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "            # torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        epoch_number += 1\n",
        "    return model, [avg_loss], [avg_vloss]\n"
      ],
      "metadata": {
        "id": "llQn6AFkS9DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a class that will assist in quickly loading the data for offline training."
      ],
      "metadata": {
        "id": "rqz70rDC-_ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CartPoleDataset(Dataset):\n",
        "    \"\"\" \n",
        "    Offline reinforcement learning dataset of Cart Pole\n",
        "    https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#afterword-torchvision\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.dataset = data\n",
        "        self.transitions, self.unique_states = self.transform_data()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.transitions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transitions[idx]\n",
        "\n",
        "    def transform_data(self):\n",
        "        states = []\n",
        "        transitions = []\n",
        "        for episode in self.dataset:\n",
        "            for transition in episode.transitions:\n",
        "                done = transition.terminal == 1.0\n",
        "                states.append(list(transition.observation))\n",
        "                value = {'state': transition.observation, 'action': transition.action, 'reward': transition.reward,\n",
        "                         'next state': transition.next_observation, 'terminal': done}\n",
        "                transitions.append(value)\n",
        "        return transitions, np.array(states)"
      ],
      "metadata": {
        "id": "dlF3umhh-9-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can set the seed for reproducibility, define the number of maximum epochs to allow the agent to train, batch size, etc."
      ],
      "metadata": {
        "id": "0SbZRFlLCj3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The antecedents or the fuzzy logic rules produced by the `unsupervised` function may change due to randomness (there may be more or less, they may behave differently, etc.). \n",
        "\n",
        "Note: You may need to do a fresh reinstantiation of the random number generators, environment, and so forth."
      ],
      "metadata": {
        "id": "FhXHKHhsArvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 39  # used in the 'human-in-the-loop' example\n",
        "MAX_EPOCHS = 20  # the maximum allowed number of epochs allowed for offline training\n",
        "BATCH_SIZE = 64  # the number of training observations to sample from the data to perform a single update\n",
        "CQL_ALPHA = 0.5  # the weight given to the CQL adjustment, a lower value is better when more data is available and vice versa\n",
        "LEARNING_RATE = 1e-3  # the learning rate used in the paper, later, a better learning rate was found which was 3e-4\n",
        "NUM_OF_TRAIN_EPISODES = 60  # the amount of training episodes that should be retrieved from CartPoleDataset to do offline training"
      ],
      "metadata": {
        "id": "GLIuzvIx_IUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add reproducibility by setting the environment seed."
      ],
      "metadata": {
        "id": "e3p-E_uZABII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Using seed {}'.format(SEED))\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "env = gym.make('CartPole-v1')\n",
        "env.seed(SEED)\n",
        "env.action_space.seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppwG7PFoAFg3",
        "outputId": "0c2d43ed-4db6-4233-8ab5-5209f04138d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using seed 39\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of states\n",
        "n_state = env.observation_space.shape[0]\n",
        "# Number of actions\n",
        "n_action = env.action_space.n"
      ],
      "metadata": {
        "id": "CbRZ-gMjAOCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Fuzzy Conservative Q-Learning algorithm to learn the Q-values."
      ],
      "metadata": {
        "id": "Vi4a6H1GX5YV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQNIB65YFO3D",
        "outputId": "f9dfb01f-6b10-4044-d848-24a99eeb3fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1` with the environment ID `CartPole-v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of training episodes available: 60\n",
            "The shape of the training data is: (3536, 4)\n",
            "\n",
            "There are 22 rules\n",
            "There are 4 antecedent terms for the 1'th input variable.\n",
            "There are 4 antecedent terms for the 2'th input variable.\n",
            "There are 4 antecedent terms for the 3'th input variable.\n",
            "There are 5 antecedent terms for the 4'th input variable.\n",
            "EPOCH 1:\n",
            "LOSS train 0.8459863810228775 valid 0.8455386044010067\n",
            "EPOCH 2:\n",
            "LOSS train 0.8455134077545706 valid 0.8444381541186788\n",
            "EPOCH 3:\n",
            "LOSS train 0.8439760767818228 valid 0.8433591693892548\n",
            "EPOCH 4:\n",
            "LOSS train 0.8426168971756172 valid 0.8422801936130441\n",
            "EPOCH 5:\n",
            "LOSS train 0.8429263288405615 valid 0.8414591213376138\n",
            "EPOCH 6:\n",
            "LOSS train 0.8394748415749449 valid 0.8403879644666077\n",
            "EPOCH 7:\n",
            "LOSS train 0.8375696922618833 valid 0.8395718607738779\n",
            "EPOCH 8:\n",
            "LOSS train 0.8419149581214616 valid 0.83869576582834\n",
            "EPOCH 9:\n",
            "LOSS train 0.8393666981754654 valid 0.8378751801329283\n",
            "EPOCH 10:\n",
            "LOSS train 0.8371126085198247 valid 0.8371777585846968\n",
            "EPOCH 11:\n",
            "LOSS train 0.8363335918220492 valid 0.8363386666141988\n",
            "EPOCH 12:\n",
            "LOSS train 0.8364813487642226 valid 0.8356630226119837\n",
            "EPOCH 13:\n",
            "LOSS train 0.8337309517070862 valid 0.8348342088099839\n",
            "EPOCH 14:\n",
            "LOSS train 0.833726175213633 valid 0.8342328882185348\n",
            "EPOCH 15:\n",
            "LOSS train 0.8326637815107762 valid 0.8336752857740453\n",
            "EPOCH 16:\n",
            "LOSS train 0.8336888232400824 valid 0.833168931334979\n",
            "EPOCH 17:\n",
            "LOSS train 0.8336505911534807 valid 0.8326890081575176\n",
            "EPOCH 18:\n",
            "LOSS train 0.8340599528932355 valid 0.8320779275441259\n",
            "EPOCH 19:\n",
            "LOSS train 0.8342185269600778 valid 0.8319341473548397\n",
            "EPOCH 20:\n",
            "LOSS train 0.8309554738167491 valid 0.8315818726480225\n"
          ]
        }
      ],
      "source": [
        "dataset, _ = get_cartpole()\n",
        "dataset = dataset[:1000]\n",
        "print('num of training episodes available: {}'.format(NUM_OF_TRAIN_EPISODES))\n",
        "# split train and test episodes\n",
        "train_episodes, val_episodes = train_test_split(dataset, test_size=0.2)\n",
        "train_episodes = train_episodes[:NUM_OF_TRAIN_EPISODES]\n",
        "\n",
        "train_data = CartPoleDataset(train_episodes)\n",
        "val_data = CartPoleDataset(val_episodes)\n",
        "\n",
        "# get replay results\n",
        "rules, _, antecedents = unsupervised(train_data.unique_states, ecm=True, Dthr=4e-1)\n",
        "\n",
        "print('There are {} rules'.format(len(rules)))\n",
        "\n",
        "for input_idx, input_variable in enumerate(antecedents):\n",
        "    print('There are {} antecedent terms for the {}\\'th input variable.'.format(len(input_variable), input_idx + 1))\n",
        "\n",
        "n_outputs = 2\n",
        "flc = MultiFLC(len(antecedents), n_outputs, antecedents, rules, learning_rate=LEARNING_RATE, cql_alpha=CQL_ALPHA)\n",
        "\n",
        "flc, train_epoch_losses, val_epoch_losses = offline_q_learning(flc, train_data,\n",
        "                                                                val_data, MAX_EPOCHS,\n",
        "                                                                BATCH_SIZE,\n",
        "                                                                gamma=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code to record the performance of the agent is from the [offline RL tutorial](https://colab.research.google.com/github/takuseno/d3rlpy/blob/master/tutorials/cartpole.ipynb#scrollTo=QcVCS0_VaqHr)."
      ],
      "metadata": {
        "id": "G6GsuCDcUJCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import glob\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "from gym.wrappers import Monitor\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "# start virtual display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "# play recorded video\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''\n",
        "            <video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")"
      ],
      "metadata": {
        "id": "1tu0fX5XV9V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your agent online! (this may take awhile if your agent is performing well)"
      ],
      "metadata": {
        "id": "PbEqz8MWX_ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap Monitor wrapper\n",
        "env = Monitor(env, './video', force=True)\n",
        "\n",
        "# evaluate\n",
        "avg_score, std_score = evaluate_on_environment(env)(flc)\n",
        "print((avg_score, std_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uG0f68GG1jB",
        "outputId": "b94b895d-4014-437c-def5-59c304414e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating online for 100 episodes.\n",
            "(500.0, 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Watch a video of how it did!"
      ],
      "metadata": {
        "id": "CoDJQ_RvYU-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_video()"
      ],
      "metadata": {
        "id": "lBHP02XvWO1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "04aad356-c6e8-42b7-c88c-6a9839561d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "            </video>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}